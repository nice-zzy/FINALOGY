# 损失函数确定过程简要说明（实验论文用）

## 1. 问题背景与候选方法

K 线图相似编码任务中，训练数据为「相似对」(anchor, positive)，仅含正样本对、无显式负样本。选取三类仅需正样本对的自监督损失函数作为候选：

| 方法 | 原理 | 防坍缩机制 | 主要超参 |
|------|------|------------|----------|
| **Barlow Twins** | 交叉相关矩阵 C 约束为对角≈1、非对角≈0 | 非对角正则化抑制冗余 | λ_off=0.005 |
| **SimSiam** | 对称负余弦 + stop-gradient | stop-gradient 打破对称，预测头非对称 | 无额外超参 |
| **VICReg** | 不变性 + 方差 + 协方差 | 方差正则防坍缩，协方差正则去相关 | λ_inv=λ_var, λ_cov=1，λ/μ 需搜索 |

三者均无需负样本，通过各自防坍缩机制学习表征，适合本任务的数据形态。

## 2. 实验流程

### 2.1 训练

- **数据**：2010–2020 训练集相似对。
- **Barlow / SimSiam**：采用原论文推荐超参（Barlow λ_off=0.005；SimSiam 无额外超参）。
- **VICReg**：固定 ν=1，对 λ=μ 做网格搜索（1, 5, 10, 25, 50），按测试集 Recall@3 选优；搜索脚本 `grid_search_vicreg_lambda.py`，选优依据为检索准确性而非训练 loss（λ 越小 loss 天然越低，不具参考价值）。

### 2.2 评估

在 2021 年测试集上计算四组相似度：

1. **原始测试集**：编码器相似度（6225 对 anchor–positive 的余弦相似度均值/标准差）；52 维相似度（同上，用制作相似对时的 52 维特征计算）。
2. **编码器检索**：以 anchor 在候选库中按编码器相似度排序，取 Top-K；计算检索到 positive 的编码器相似度及 52 维相似度，考察检索结果与 52 维定义的一致性。

检索指标：Recall@1、Recall@3（真实 positive 在 Top-K 内的比例）。

## 3. 选优结论

| 方法 | 原始相似对编码器相似度 | 检索与 52 维一致性 | 收敛速度 |
|------|------------------------|--------------------|----------|
| SimSiam | 最高（≈0.98） | 中等 | 快（≈17 轮） |
| VICReg | 略低（≈0.78） | 最好（≈0.91） | 中等 |
| Barlow | 良好（≈0.975） | 一般 | 中等 |

- **若强调「相似对拟合」**：SimSiam 最优。
- **若强调「检索与 52 维定义的相似一致」**：VICReg 最优。
- **折中**：Barlow 介于二者之间。

## 4. 实验设置与可复现

- **共同设置**：batch_size=32，learning_rate=5e-5（或同量级），编码器架构一致。
- **VICReg 网格搜索**：`services/training/scripts/grid_search_vicreg_lambda.py`，结果输出至 `logs/vicreg_grid/run_*/grid_results.json`。
- **验证脚本**：`services/training/evaluate/validate_model.py`，可指定 `--features-52d` 以输出 52 维相似度与 Recall。
